{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Sample = list[int | float]\n",
    "type Data = list[Sample]\n",
    "\n",
    "type Target = int | float\n",
    "type Targets = list[Target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ActivationBase(ABC):\n",
    "    @abstractmethod\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        \"\"\"Apply the activation function to an layer output\"\"\"\n",
    "        pass\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "class ReLU(ActivationBase):\n",
    "    def calc(self, x) -> list[float]:\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "\n",
    "class ELU(ActivationBase):\n",
    "    def __init__(self, alpha: float = 1.0) -> None:\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return np.where(x > 0, x, self.alpha * (np.exp(x) - 1))\n",
    "\n",
    "\n",
    "class Sigmoid(ActivationBase):\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class Tahn(ActivationBase):\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return np.tanh(x)\n",
    "\n",
    "\n",
    "class Softmax(ActivationBase):\n",
    "    \"\"\"returns model 'probabilities' for each class\"\"\"\n",
    "\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        \n",
    "        # optimization: make numbers in an array from -inf to 0 because of a np.exp growing\n",
    "        # and returns an array of floats from 0.0 to 1.0\n",
    "        max_value = np.max(x)\n",
    "        x -= max_value\n",
    "\n",
    "        exp_values = np.exp(x)\n",
    "        return exp_values / np.sum(exp_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "\n",
    "\n",
    "class LossBase(ABC):\n",
    "    @abstractmethod\n",
    "    def calc(self, x: Sample, y: Targets) -> float:\n",
    "        \"\"\"Apply the loss function to an output layer\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class MSELoss(LossBase):\n",
    "    \"\"\"For regression\"\"\"\n",
    "    def __init__(self, reduction: Literal['sum', 'mean'] = 'mean') -> None:\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def calc(self, x: Sample, y: Targets) -> float:\n",
    "\n",
    "        x = np.array(x)\n",
    "        loss = (x - y) ** 2\n",
    "\n",
    "        if self.reduction == 'sum':\n",
    "            return np.sum(loss)\n",
    "        elif self.reduction == 'mean':\n",
    "            return np.mean(loss)\n",
    "\n",
    "\n",
    "class CrossEntropy(LossBase):\n",
    "    \"\"\"For classification\"\"\"\n",
    "    def calc(self, x: Sample, y: Targets) -> float:\n",
    "        return -np.sum(y * np.log(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.39262147e-44 7.31058579e-01 9.74950551e-35 2.68941421e-01]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = [1, 100, 22, 99]\n",
    "\n",
    "f = Softmax()\n",
    "\n",
    "b = f.calc(a)\n",
    "print(b)\n",
    "print(sum(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data: Data, target_list: Targets) -> None:\n",
    "        self.data: Data = data\n",
    "        self._len = len(data)\n",
    "        self.target_list: Targets = target_list\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, index) -> Sample:\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_inputs: int, n_neurons: int, activation: ActivationBase) -> None:\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_neurons = n_neurons\n",
    "        \n",
    "        self.weights = self._init_weights()\n",
    "        self.biases = self._init_biases()\n",
    "        self.output = []\n",
    "\n",
    "        self.activation = activation\n",
    "    \n",
    "    def _init_weights(self) -> list[float]:\n",
    "        return np.random.randn(self.n_inputs, self.n_neurons) * 0.1\n",
    "    \n",
    "    def _init_biases(self):\n",
    "        return np.random.randn(self.n_neurons)\n",
    "    \n",
    "    def forward(self, inputs) -> None:\n",
    "        print(f\"{inputs = }\")\n",
    "        print(f\"{self.weights = }\")\n",
    "        print(f\"{self.biases = }\")\n",
    "        output = np.dot(inputs, self.weights)\n",
    "\n",
    "        print(f\"{output = }\")\n",
    "\n",
    "        output += self.biases\n",
    "        # output = output + self.biases\n",
    "\n",
    "\n",
    "        self.output = self.activation.calc(output)\n",
    "        print(f\"{self.output = }\")\n",
    "\n",
    "\n",
    "type Layers = list[Linear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers: Layers, loss: LossBase):\n",
    "        self.layers = layers\n",
    "        self._layers_len = len(layers)\n",
    "        self.loss = loss\n",
    "\n",
    "    def fit(self, dataset: Dataset):\n",
    "        losses = []\n",
    "\n",
    "        for i,sample in enumerate(dataset):\n",
    "            print(\"_______ Layer\", 1, '\\n\\n')\n",
    "            self.layers[0].forward(inputs=sample)\n",
    "            \n",
    "            for j in range(1, self._layers_len):\n",
    "                print(\"______ Layer\", j+1, '\\n\\n')\n",
    "                self.layers[j].forward(inputs=self.layers[j-1].output)\n",
    "\n",
    "            targets = dataset.target_list[i]\n",
    "            \n",
    "            # Calc loss\n",
    "            loss = self.calc_loss(targets=targets)\n",
    "            losses.append(loss)\n",
    "    \n",
    "    def predict(self):\n",
    "        ...\n",
    "    \n",
    "    def calc_loss(self, targets: Target) -> float:\n",
    "        output_layer = self.layers[-1]\n",
    "        output = output_layer.output\n",
    "\n",
    "        loss = self.loss.calc(x=output, y=targets)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights.append(layer.weights)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\n",
    "    # [1,2,3,4],\n",
    "    [4,3,2,1]\n",
    "]\n",
    "y_train = [1,]\n",
    "\n",
    "\n",
    "X_val = [\n",
    "    [1,2,3,4],\n",
    "    # [4,3,2,1]\n",
    "]\n",
    "y_val = [1,]\n",
    "\n",
    "\n",
    "train_dataset = Dataset(data=X_train, target_list=y_train)\n",
    "# val_dataset = Dataset(data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Linear(4,2, activation=ReLU()),\n",
    "    Linear(2,4, activation=ReLU()),\n",
    "    Linear(4,1, activation=Softmax()),\n",
    "]\n",
    "\n",
    "model = Model(layers=layers, loss=MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ Layer 1 \n",
      "\n",
      "\n",
      "inputs = [4, 3, 2, 1]\n",
      "self.weights = array([[-0.06112152, -0.12514491],\n",
      "       [ 0.00027964, -0.00702919],\n",
      "       [ 0.05637999,  0.11993163],\n",
      "       [ 0.08326192, -0.07656556]])\n",
      "self.biases = array([-0.82065462, -0.55801214])\n",
      "output = array([-0.04762527, -0.35836952])\n",
      "self.output = array([0., 0.])\n",
      "______ Layer 2 \n",
      "\n",
      "\n",
      "inputs = array([0., 0.])\n",
      "self.weights = array([[ 0.00430376, -0.18055517, -0.21157959,  0.01160333],\n",
      "       [-0.11759506,  0.11392518, -0.06527293, -0.01540884]])\n",
      "self.biases = array([ 0.04182254,  0.30385591, -1.04609445,  2.72200013])\n",
      "output = array([0., 0., 0., 0.])\n",
      "self.output = array([0.04182254, 0.30385591, 0.        , 2.72200013])\n",
      "______ Layer 3 \n",
      "\n",
      "\n",
      "inputs = array([0.04182254, 0.30385591, 0.        , 2.72200013])\n",
      "self.weights = array([[-0.11583948],\n",
      "       [-0.07725544],\n",
      "       [-0.07515247],\n",
      "       [ 0.1083649 ]])\n",
      "self.biases = array([-0.09594633])\n",
      "output = array([0.26665005])\n",
      "self.output = array([1.])\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
