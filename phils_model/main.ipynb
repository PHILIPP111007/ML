{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Sample = list[int | float]\n",
    "type Data = list[Sample]\n",
    "\n",
    "type Target = int | float\n",
    "type Targets = list[Target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ActivationBase(ABC):\n",
    "    @abstractmethod\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        \"\"\"Apply the activation function to an layer output\"\"\"\n",
    "        pass\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "class ReLU(ActivationBase):\n",
    "    def calc(self, x) -> list[float]:\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "\n",
    "class ELU(ActivationBase):\n",
    "    def __init__(self, alpha: float = 1.0) -> None:\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return np.where(x > 0, x, self.alpha * (np.exp(x) - 1))\n",
    "\n",
    "\n",
    "class Sigmoid(ActivationBase):\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class Tahn(ActivationBase):\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return np.tanh(x)\n",
    "\n",
    "\n",
    "class Softmax(ActivationBase):\n",
    "    \"\"\"returns model 'probabilities' for each class\"\"\"\n",
    "\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        \n",
    "        # optimization: make numbers in an array from -inf to 0 because of a np.exp growing\n",
    "        # and returns an array of floats from 0.0 to 1.0\n",
    "        max_value = np.max(x)\n",
    "        x -= max_value\n",
    "\n",
    "        exp_values = np.exp(x)\n",
    "        return exp_values / np.sum(exp_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "\n",
    "\n",
    "class LossBase(ABC):\n",
    "    @abstractmethod\n",
    "    def calc(self, x: Sample, y: Targets) -> float:\n",
    "        \"\"\"Apply the loss function to an output layer\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class MSELoss(LossBase):\n",
    "    \"\"\"For regression\"\"\"\n",
    "    def __init__(self, reduction: Literal['sum', 'mean'] = 'mean') -> None:\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def calc(self, x: Sample, y: Targets) -> float:\n",
    "\n",
    "        x = np.array(x)\n",
    "        loss = (x - y) ** 2\n",
    "\n",
    "        if self.reduction == 'sum':\n",
    "            return np.sum(loss)\n",
    "        elif self.reduction == 'mean':\n",
    "            return np.mean(loss)\n",
    "\n",
    "\n",
    "class CrossEntropy(LossBase):\n",
    "    \"\"\"For classification\"\"\"\n",
    "    def calc(self, x: Sample, y: Targets) -> float:\n",
    "        return -np.sum(y * np.log(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.39262147e-44 7.31058579e-01 9.74950551e-35 2.68941421e-01]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = [1, 100, 22, 99]\n",
    "\n",
    "f = Softmax()\n",
    "\n",
    "b = f.calc(a)\n",
    "print(b)\n",
    "print(sum(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data: Data, target_list: Targets) -> None:\n",
    "        self.data: Data = data\n",
    "        self._len = len(data)\n",
    "        self.target_list: Targets = target_list\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, index) -> Sample:\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_inputs: int, n_neurons: int, activation: ActivationBase) -> None:\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_neurons = n_neurons\n",
    "        \n",
    "        self.weights = self._init_weights()\n",
    "        self.biases = self._init_biases()\n",
    "        self.output = []\n",
    "\n",
    "        self.activation = activation\n",
    "    \n",
    "    def _init_weights(self) -> list[float]:\n",
    "        return np.random.randn(self.n_inputs, self.n_neurons) * 0.1\n",
    "    \n",
    "    def _init_biases(self):\n",
    "        return np.random.randn(self.n_neurons)\n",
    "    \n",
    "    def forward(self, inputs) -> None:\n",
    "        # print(f\"{inputs = }\")\n",
    "        # print(f\"{self.weights = }\")\n",
    "        # print(f\"{self.biases = }\")\n",
    "        output = np.dot(inputs, self.weights)\n",
    "\n",
    "        # print(f\"{output = }\")\n",
    "\n",
    "        output += self.biases\n",
    "        # output = output + self.biases\n",
    "\n",
    "\n",
    "        self.output = self.activation.calc(output)\n",
    "        # print(f\"{self.output = }\")\n",
    "\n",
    "\n",
    "type Layers = list[Linear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers: Layers, loss: LossBase, n_epoch: int = 1, verbose: bool = True):\n",
    "        self.layers = layers\n",
    "        self._layers_len = len(layers)\n",
    "        self.loss = loss\n",
    "        \n",
    "        self.n_epoch = n_epoch\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, dataset: Dataset):\n",
    "        losses = []\n",
    "\n",
    "        range_epoch = range(self.n_epoch)\n",
    "        if self.verbose:\n",
    "            range_epoch = tqdm(range_epoch, desc=\"epochs\", position=0)\n",
    "\n",
    "        for epoch in range_epoch:\n",
    "            for i,sample in enumerate(dataset):\n",
    "                # print(\"Layer\", 1, '\\n\\n')\n",
    "\n",
    "                self.layers[0].forward(inputs=sample)\n",
    "                \n",
    "                for j in range(1, self._layers_len):\n",
    "                    # print(\"Layer\", j+1, '\\n\\n')\n",
    "                    \n",
    "                    self.layers[j].forward(inputs=self.layers[j-1].output)\n",
    "\n",
    "                targets = dataset.target_list[i]\n",
    "                \n",
    "                # Calc loss\n",
    "                loss = self.calc_loss(targets=targets)\n",
    "                losses.append(loss)\n",
    "    \n",
    "    def predict(self):\n",
    "        ...\n",
    "    \n",
    "    def calc_loss(self, targets: Target) -> float:\n",
    "        output_layer = self.layers[-1]\n",
    "        output = output_layer.output\n",
    "\n",
    "        loss = self.loss.calc(x=output, y=targets)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights.append(layer.weights)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\n",
    "    # [1,2,3,4],\n",
    "    [4,3,2,1]\n",
    "]\n",
    "y_train = [1,]\n",
    "\n",
    "\n",
    "X_val = [\n",
    "    [1,2,3,4],\n",
    "    # [4,3,2,1]\n",
    "]\n",
    "y_val = [1,]\n",
    "\n",
    "\n",
    "train_dataset = Dataset(data=X_train, target_list=y_train)\n",
    "# val_dataset = Dataset(data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Linear(4,2, activation=ReLU()),\n",
    "    Linear(2,4, activation=ReLU()),\n",
    "    Linear(4,1, activation=Softmax()),\n",
    "]\n",
    "\n",
    "model = Model(layers=layers, loss=MSELoss(), n_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 100000/100000 [00:03<00:00, 27419.57it/s]\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
