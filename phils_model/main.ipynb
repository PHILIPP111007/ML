{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypeAlias\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample: TypeAlias = list[int | float]\n",
    "Data: TypeAlias = list[Sample]\n",
    "\n",
    "Target: TypeAlias = int | float\n",
    "Targets: TypeAlias = list[Target]\n",
    "\n",
    "Weights: TypeAlias = list[list[float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ActivationBase(ABC):\n",
    "    @abstractmethod\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        \"\"\"Apply the activation function to an layer output\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def derivative(self, x: Sample):\n",
    "        pass\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "class ReLU(ActivationBase):\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def derivative(self, x: Sample):\n",
    "        return self.calc(x=x)\n",
    "\n",
    "\n",
    "class Sigmoid(ActivationBase):\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def derivative(self, x: Sample):\n",
    "        return x * (1-x)\n",
    "\n",
    "\n",
    "class Softmax(ActivationBase):\n",
    "    \"\"\"returns model 'probabilities' for each class\"\"\"\n",
    "\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        \n",
    "        # optimization: make numbers in an array from -inf to 0 because of a np.exp growing\n",
    "        # and returns an array of floats from 0.0 to 1.0\n",
    "        max_value = np.max(x)\n",
    "        x -= max_value\n",
    "\n",
    "        exp_values = np.exp(x)\n",
    "        return exp_values / np.sum(exp_values)\n",
    "    \n",
    "    def derivative(self, x: Sample):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "\n",
    "\n",
    "class LossBase(ABC):\n",
    "    @abstractmethod\n",
    "    def calc(self, x: Sample, y: Target) -> float:\n",
    "        \"\"\"Apply the loss function to an output layer\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class MSELoss(LossBase):\n",
    "    \"\"\"For regression\"\"\" \n",
    "    def calc(self, x: Sample, y: Target) -> float:\n",
    "\n",
    "        x = np.argmax(x) + 1\n",
    "        y = np.argmax(y)  +1\n",
    "\n",
    "        loss = (y - x) ** 2\n",
    "\n",
    "        return np.mean(loss)\n",
    "\n",
    "\n",
    "class CrossEntropy(LossBase):\n",
    "    \"\"\"For classification\"\"\"\n",
    "    def calc(self, x: Sample, y: Target) -> float:\n",
    "        return -np.sum(y * np.log(x + 0.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.39262147e-44 7.31058579e-01 9.74950551e-35 2.68941421e-01]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = [1, 100, 22, 99]\n",
    "\n",
    "f = Softmax()\n",
    "\n",
    "b = f.calc(a)\n",
    "print(b)\n",
    "print(sum(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data: Data, targets: Targets) -> None:\n",
    "        self.data: Data = data\n",
    "        self._len = len(data)\n",
    "        self.targets: Targets = targets\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, index) -> Sample:\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_inputs: int, n_neurons: int, activation: ActivationBase) -> None:\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_neurons = n_neurons\n",
    "        \n",
    "        self.weights = self._init_weights()\n",
    "        self.bias = self._init_bias()\n",
    "        self.output = []\n",
    "\n",
    "        self.activation = activation\n",
    "    \n",
    "    def _init_weights(self) -> list[float]:\n",
    "        weights = np.random.randn(self.n_neurons, self.n_inputs) * 0.1\n",
    "        return weights\n",
    "    \n",
    "    def _init_bias(self) -> list[float]:\n",
    "        return np.random.randn(1)\n",
    "    \n",
    "    def forward(self, inputs) -> None:\n",
    "        output = np.dot( self.weights, inputs)\n",
    "        output += self.bias\n",
    "        self.output = self.activation.calc(output)\n",
    "\n",
    "\n",
    "Layers: TypeAlias = list[Linear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers: Layers, loss: LossBase):\n",
    "        self.layers = layers\n",
    "        self._layers_len = len(layers)\n",
    "        self.loss = loss\n",
    "    \n",
    "    def fit(self, dataset: Dataset, n_epoch: int = 1, learning_rate: float = 0.01, verbose: bool = True) -> list[float]:\n",
    "        losses_by_epoch = []\n",
    "\n",
    "        range_epoch = range(n_epoch)\n",
    "        if verbose:\n",
    "            range_epoch = tqdm(range_epoch, desc=\"epochs\", position=0)\n",
    "\n",
    "        for epoch in range_epoch:\n",
    "            epoch_losses = []\n",
    "\n",
    "            for i,sample in enumerate(dataset):\n",
    "                sample = np.array(sample)\n",
    "\n",
    "                # Forward pass\n",
    "                self.layers[0].forward(inputs=sample) # input layer\n",
    "                for j in range(1, self._layers_len):\n",
    "                    self.layers[j].forward(inputs=self.layers[j-1].output)\n",
    "\n",
    "                target = dataset.targets[i]\n",
    "\n",
    "\n",
    "                # Calc loss\n",
    "                output_error = self.calc_loss(target=target)\n",
    "                epoch_losses.append(output_error)\n",
    "\n",
    "                # Backward pass\n",
    "                D = []\n",
    "                delta = output_error * self.layers[-2].activation.derivative(x=self.layers[-1].output)\n",
    "                D.append(delta)\n",
    "                for i in range(self._layers_len - 2, -1, -1):\n",
    "                    # error = np.dot(self.layers[i+1].weights.T, delta)\n",
    "                    # delta =  self.layers[i].activation.derivative(x=self.layers[i].output) * error\n",
    "                    # self.layers[i+1].weights += np.dot(delta, self.layers[i].output.T) * learning_rate\n",
    "\n",
    "                    delta = np.dot(D[-1], self.layers[i-1].weights)\n",
    "                    delta *= self.layers[i].activation.derivative(self.layers[i].output)\n",
    "                    D.append(delta)\n",
    "                \n",
    "                # Update weights\n",
    "                D = D[::-1]\n",
    "                for i in range(self._layers_len):\n",
    "                    self.layers[i].weights += np.dot(D[i], self.layers[i].output) * learning_rate\n",
    "                # print(D)\n",
    "\n",
    "            mean_loss = np.mean(epoch_losses)\n",
    "            losses_by_epoch.append(mean_loss)\n",
    "        \n",
    "        return losses_by_epoch\n",
    "    \n",
    "    def predict(self, sample: Sample) -> list[float]:\n",
    "        sample = np.array(sample)\n",
    "\n",
    "        self.layers[0].forward(inputs=sample)\n",
    "                \n",
    "        for i in range(1, self._layers_len):\n",
    "            self.layers[i].forward(inputs=self.layers[i-1].output)\n",
    "        \n",
    "        predict = self.layers[-1].output\n",
    "        return predict\n",
    "    \n",
    "    def calc_loss(self, target: Target) -> float:\n",
    "        output_layer = self.layers[-1]\n",
    "        output = output_layer.output\n",
    "\n",
    "        # print(output, target)\n",
    "\n",
    "        loss = self.loss.calc(x=output, y=target)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def set_weights(self, weights: Weights) -> None:\n",
    "        for w,layer in zip(weights, self.layers):\n",
    "            layer.weights = w\n",
    "\n",
    "    @property\n",
    "    def weights(self) -> Weights:\n",
    "        weights = [layer.weights for layer in self.layers]\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset['data'], dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0), np.int64(1), np.int64(2)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set(y)\n",
    "labels_len = len(labels)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 = []\n",
    "\n",
    "for i in y:\n",
    "    l = [0] * labels_len\n",
    "    l[i] = 1\n",
    "    y_1.append(l)\n",
    "y_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y_1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data=X_train, targets=y_train)\n",
    "val_dataset = Dataset(data=X_val, targets=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Linear(4,1, activation=Sigmoid()),\n",
    "    Linear(1,3, activation=Softmax()),\n",
    "]\n",
    "\n",
    "model = Model(layers=layers, loss=MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(1.6)]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = model.fit(dataset=train_dataset, n_epoch=1, learning_rate=0.01, verbose=0)\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(1.6)]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5. , 3.4, 1.6, 0.4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([nan, nan, nan]), [0, 1, 0])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train[1]), y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample,target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_train, y_train):\n\u001b[1;32m      5\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(sample\u001b[38;5;241m=\u001b[39msample)\n\u001b[0;32m----> 7\u001b[0m     pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(pred[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(pred)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print(target)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(pred) \u001b[38;5;241m==\u001b[39m target:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "all_count = 0\n",
    "\n",
    "for sample,target in zip(X_train, y_train):\n",
    "    pred = model.predict(sample=sample)\n",
    "\n",
    "    pred = np.where(pred[0] >= max(pred[0]), 1, 0)\n",
    "    # print(pred)\n",
    "    # print(target)\n",
    "\n",
    "    if list(pred) == target:\n",
    "        true_count += 1\n",
    "    all_count += 1 \n",
    "\n",
    "\n",
    "acc = true_count / all_count\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
