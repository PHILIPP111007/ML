{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypeAlias\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample: TypeAlias = list[int | float]\n",
    "Data: TypeAlias = list[Sample]\n",
    "\n",
    "Target: TypeAlias = int | float\n",
    "Targets: TypeAlias = list[Target]\n",
    "\n",
    "Weights: TypeAlias = list[list[float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ActivationBase(ABC):\n",
    "    @abstractmethod\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        \"\"\"Apply the activation function to an layer output\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def derivative(self, x: Sample):\n",
    "        pass\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "class ReLU(ActivationBase):\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def derivative(self, x: Sample):\n",
    "        return self.calc(x=x)\n",
    "\n",
    "\n",
    "class Sigmoid(ActivationBase):\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def derivative(self, x: Sample):\n",
    "        return x * (1-x)\n",
    "\n",
    "\n",
    "class Softmax(ActivationBase):\n",
    "    \"\"\"returns model 'probabilities' for each class\"\"\"\n",
    "\n",
    "    def calc(self, x: Sample) -> list[float]:\n",
    "        \n",
    "        # optimization: make numbers in an array from -inf to 0 because of a np.exp growing\n",
    "        # and returns an array of floats from 0.0 to 1.0\n",
    "        max_value = np.max(x)\n",
    "        x -= max_value\n",
    "\n",
    "        exp_values = np.exp(x)\n",
    "        return exp_values / np.sum(exp_values)\n",
    "    \n",
    "    def derivative(self, x: Sample):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "\n",
    "\n",
    "class LossBase(ABC):\n",
    "    @abstractmethod\n",
    "    def calc(self, x: Sample, y: Target) -> float:\n",
    "        \"\"\"Apply the loss function to an output layer\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class MSELoss(LossBase):\n",
    "    \"\"\"For regression\"\"\" \n",
    "    def calc(self, x: Sample, y: Target) -> float:\n",
    "\n",
    "        loss = (y - x) ** 2\n",
    "\n",
    "        return np.mean(loss)\n",
    "\n",
    "\n",
    "class CrossEntropy(LossBase):\n",
    "    \"\"\"For classification\"\"\"\n",
    "    def calc(self, x: Sample, y: Target) -> float:\n",
    "        return -np.sum(y * np.log(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.39262147e-44 7.31058579e-01 9.74950551e-35 2.68941421e-01]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = [1, 100, 22, 99]\n",
    "\n",
    "f = Softmax()\n",
    "\n",
    "b = f.calc(a)\n",
    "print(b)\n",
    "print(sum(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data: Data, targets: Targets) -> None:\n",
    "        self.data: Data = data\n",
    "        self._len = len(data)\n",
    "        self.targets: Targets = targets\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, index) -> Sample:\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_inputs: int, n_neurons: int, activation: ActivationBase) -> None:\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_neurons = n_neurons\n",
    "        \n",
    "        self.weights = self._init_weights()\n",
    "        self.bias = self._init_bias()\n",
    "        self.output = []\n",
    "\n",
    "        self.activation = activation\n",
    "    \n",
    "    def _init_weights(self) -> list[float]:\n",
    "        scale = 1/max(1., (2+2)/2.)\n",
    "        limit = np.sqrt(3.0 * scale)\n",
    "\n",
    "        # return np.random.randn(self.n_neurons, self.n_inputs) #* 0.1\n",
    "    \n",
    "        weights = np.random.uniform(-limit, limit, size=(self.n_neurons, self.n_inputs))\n",
    "        return weights\n",
    "    \n",
    "    def _init_bias(self) -> list[float]:\n",
    "        return np.random.randn(1)\n",
    "    \n",
    "    def forward(self, inputs) -> None:\n",
    "        # print(f\"{inputs = }\")\n",
    "        # print(f\"{self.weights = }\")\n",
    "\n",
    "        output = np.matmul( self.weights, inputs.T)\n",
    "\n",
    "        output += self.bias\n",
    "\n",
    "        self.output = self.activation.calc(output)\n",
    "        # print(f\"{self.output = }\")\n",
    "    \n",
    "\n",
    "    # def backward(self, grad, learning_rate: float, output):\n",
    "        \n",
    "    #     # print(f\"{self.weights = }\")\n",
    "    #     print(f\"{output = }\")\n",
    "    #     print(f\"{grad = }\")\n",
    "\n",
    "    #     print()\n",
    "\n",
    "    #     weights_new = self.weights - grad * output * learning_rate\n",
    "    #     # print(f\"{weights_new = }\")\n",
    "    #     # print('\\n\\n')\n",
    "\n",
    "    #     self.weights = weights_new\n",
    "\n",
    "\n",
    "Layers: TypeAlias = list[Linear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers: Layers, loss: LossBase, n_epoch: int = 1, learning_rate: float = 0.01, verbose: bool = True):\n",
    "        self.layers = layers\n",
    "        self._layers_len = len(layers)\n",
    "        self.loss = loss\n",
    "        \n",
    "        self.n_epoch = n_epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, dataset: Dataset) -> list[float]:\n",
    "        losses_by_epoch = []\n",
    "\n",
    "        range_epoch = range(self.n_epoch)\n",
    "        if self.verbose:\n",
    "            range_epoch = tqdm(range_epoch, desc=\"epochs\", position=0)\n",
    "\n",
    "        for epoch in range_epoch:\n",
    "            epoch_losses = []\n",
    "\n",
    "            for i,sample in enumerate(dataset):\n",
    "                sample = np.array(sample)\n",
    "                # sample = sample.reshape(1,len(sample))\n",
    "\n",
    "\n",
    "                # Forward pass\n",
    "                self.layers[0].forward(inputs=sample) # input layer\n",
    "                for j in range(1, self._layers_len):\n",
    "                    self.layers[j].forward(inputs=self.layers[j-1].output)\n",
    "\n",
    "                target = dataset.targets[i]\n",
    "                \n",
    "\n",
    "                # Calc loss\n",
    "                output_error = self.calc_loss(target=target)\n",
    "                epoch_losses.append(output_error)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                # Backward pass\n",
    "                # backward from output to input layer\n",
    "                # propagate gradients using chain rule\n",
    "\n",
    "                delta =  self.layers[-2].activation.derivative(x=self.layers[-1].output) * output_error\n",
    "\n",
    "                for i in range(self._layers_len - 2, 0, -1):\n",
    "                    print(\"weights\", self.layers[i+1].weights)\n",
    "                    print(\"delta\", delta)\n",
    "\n",
    "                    error = np.dot(self.layers[i+1].weights.T, delta)\n",
    "                    delta =  self.layers[i].activation.derivative(x=self.layers[i].output) * error\n",
    "\n",
    "                    # self.layers[i+1]\n",
    "                    \n",
    "            mean_loss = np.mean(epoch_losses)\n",
    "            losses_by_epoch.append(mean_loss)\n",
    "        \n",
    "        return losses_by_epoch\n",
    "    \n",
    "    def predict(self, sample: Sample) -> list[float]:\n",
    "        sample = np.array(sample)\n",
    "        sample = sample.reshape(1,len(sample))\n",
    "\n",
    "        self.layers[0].forward(inputs=sample)\n",
    "                \n",
    "        for j in range(1, self._layers_len):\n",
    "            self.layers[j].forward(inputs=self.layers[j-1].output)\n",
    "        \n",
    "        predict = self.layers[-1].output\n",
    "        return predict\n",
    "    \n",
    "    def calc_loss(self, target: Target) -> float:\n",
    "        output_layer = self.layers[-1]\n",
    "        output = output_layer.output\n",
    "\n",
    "        loss = self.loss.calc(x=output, y=target)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def set_weights(self, weights: Weights) -> None:\n",
    "        for w,layer in zip(weights, self.layers):\n",
    "            layer.weights = w\n",
    "\n",
    "    @property\n",
    "    def weights(self) -> Weights:\n",
    "        weights = [layer.weights for layer in self.layers]\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\n",
    "    # [1,2,3,4],\n",
    "    [4,3,2,1]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# X_train = [\n",
    "#     [[1,2,3], [1,2,3], [1,2,3]], # photo\n",
    "# ]\n",
    "\n",
    "y_train = [1,]\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Dataset(data=X_train, targets=y_train)\n",
    "# val_dataset = Dataset(data=X_val, targets=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [[0.98922012]]\n",
      "delta [0.]\n",
      "weights [[-1.1027246]]\n",
      "delta [0.]\n",
      "weights [[-0.71061908 -0.90337474 -0.26092541  0.75022038  0.19218836 -0.16157973\n",
      "  -0.86220984 -0.56044209  0.51798827 -0.04515772  0.42738035  0.43078864\n",
      "   1.1378959  -0.2155129  -0.69536619  0.61184062  0.7716131   0.23898331\n",
      "  -0.8490155  -0.11401803  1.18117661 -0.83250931  0.32595073 -1.07884529\n",
      "   0.9534285  -1.08374539  0.35926728  1.00532671 -1.08358968  0.27433708\n",
      "  -0.51998205 -0.70302348  0.61020996  0.36907327 -0.17858175  0.43997014\n",
      "   0.79547082 -0.34956048 -0.15004788  0.147363    0.96763968  0.5294663\n",
      "  -0.41667789 -0.12258554 -0.93361612  0.31398528 -0.2807096   0.67172133\n",
      "  -0.41391285 -0.14374035  0.01680576 -0.85726241  0.24078391 -0.72716076\n",
      "   1.2008945   0.19110736 -0.58107663 -0.66516595 -0.63747592 -1.1206695\n",
      "  -0.35505441  0.56215466  0.39363403  0.45298507 -0.46427331 -0.42338011\n",
      "   0.9882086  -0.20033137  0.75674208  0.33920965  0.02872272 -0.5219441\n",
      "  -0.39601342  0.00262892  0.78663189 -0.81190644 -0.96407452  0.69891204\n",
      "  -1.06707523 -0.30230652  0.068771   -0.54074609  0.68890445 -1.09308168\n",
      "  -0.07548989  0.24509284 -0.3847439  -0.64413839  1.03314089 -0.68132893\n",
      "   1.14952843 -0.37595139  0.23074869  0.89978336 -0.5196385   1.13020289\n",
      "   0.47875544  1.07925866  0.68705937  0.70129009]]\n",
      "delta [-0.]\n",
      "weights [[-0.76891901 -0.26100899]\n",
      " [ 0.20482754  0.21947357]\n",
      " [ 0.6086069  -0.97157332]\n",
      " [-0.23664676  1.08045231]\n",
      " [ 1.00955627 -0.50248347]\n",
      " [-1.19472331  1.06024623]\n",
      " [ 0.70556121  0.12705056]\n",
      " [ 0.67860248  1.13387662]\n",
      " [ 0.43740141  0.05949633]\n",
      " [ 0.60736714 -0.38595474]\n",
      " [-0.28680018 -0.33490958]\n",
      " [-0.78354592  0.77674301]\n",
      " [-0.17928184 -0.49610516]\n",
      " [-0.96750256  0.61897402]\n",
      " [-0.80868506  0.0996331 ]\n",
      " [-0.33120636  1.20452251]\n",
      " [ 0.22248601  1.07466395]\n",
      " [-0.4549131  -0.88616191]\n",
      " [ 0.76298867 -0.23016114]\n",
      " [ 1.00876201 -0.69034135]\n",
      " [ 0.94287657  0.94918776]\n",
      " [-0.18851664 -0.1737365 ]\n",
      " [-0.42451837 -0.29226861]\n",
      " [ 0.91445032  0.96396113]\n",
      " [ 0.37343893 -0.11614618]\n",
      " [-1.03665923  0.39361433]\n",
      " [-0.95143348 -0.13661848]\n",
      " [ 0.83647712  0.67932838]\n",
      " [-0.70774269 -0.45977981]\n",
      " [-0.19757743 -0.21846373]\n",
      " [ 0.46322927  1.11472543]\n",
      " [ 0.07795525 -0.77687829]\n",
      " [-1.06593376 -0.51807256]\n",
      " [-0.16371116 -0.98886644]\n",
      " [-0.40563295 -0.47341861]\n",
      " [ 0.72931755  1.03967633]\n",
      " [-0.92692981 -0.13760678]\n",
      " [-0.13395263  0.09440405]\n",
      " [ 0.95521825 -0.9193242 ]\n",
      " [-0.97072524  0.73733847]\n",
      " [ 0.75777328 -0.2850703 ]\n",
      " [ 1.01777967 -0.13175735]\n",
      " [-1.07619673  0.70556251]\n",
      " [ 0.07632875  0.11577094]\n",
      " [-0.35899977 -0.70705777]\n",
      " [-1.02183136  0.17945047]\n",
      " [-0.04651959  0.81505464]\n",
      " [-0.48075628  0.17654731]\n",
      " [-0.71313043  0.53461627]\n",
      " [-0.241468   -0.53647184]\n",
      " [ 1.08129665  0.26813123]\n",
      " [-0.81065098  0.59828539]\n",
      " [ 0.16434748 -0.47380985]\n",
      " [ 0.76306258  0.63199294]\n",
      " [ 1.07075119 -0.14535722]\n",
      " [-0.27017899 -0.36302013]\n",
      " [ 0.37400076  0.52537864]\n",
      " [ 0.1761448  -0.20442636]\n",
      " [-0.06631425  0.0522821 ]\n",
      " [-0.66671797 -1.10494286]\n",
      " [-0.26119091  0.77236131]\n",
      " [-0.55071496  0.08118338]\n",
      " [-0.71658064 -1.08531888]\n",
      " [ 0.9148669   0.46452537]\n",
      " [ 0.49934373 -0.86296703]\n",
      " [ 0.06804306 -0.63696171]\n",
      " [ 0.19321042  1.08360127]\n",
      " [ 0.09453938 -0.69793431]\n",
      " [ 0.68024409 -1.17209986]\n",
      " [-0.52114933  0.5848869 ]\n",
      " [ 0.3908243  -0.36133645]\n",
      " [ 0.50183847  0.5638168 ]\n",
      " [-0.29453685  0.66795644]\n",
      " [-0.68028937  0.22753354]\n",
      " [ 0.82214698 -0.22234984]\n",
      " [ 0.78592643  0.88628918]\n",
      " [ 0.79542593 -0.55364276]\n",
      " [-0.22311521  0.99388179]\n",
      " [-1.00927154 -0.68180767]\n",
      " [-0.61953135  0.81078812]\n",
      " [ 0.42753008  0.4313178 ]\n",
      " [-0.64075051 -0.71069242]\n",
      " [-0.92072328  0.05850605]\n",
      " [-0.37206782  0.53198674]\n",
      " [ 0.35987619 -1.02511912]\n",
      " [ 0.55996329  1.10873594]\n",
      " [ 0.80237538 -1.07943445]\n",
      " [-0.87161672 -1.04321944]\n",
      " [ 1.22178603 -0.58745228]\n",
      " [ 1.07997137 -1.06307317]\n",
      " [ 1.21893292  0.98488688]\n",
      " [-0.5938045  -0.0121268 ]\n",
      " [ 0.91992119  1.13984705]\n",
      " [ 0.90595345  0.89625339]\n",
      " [-0.52065572  0.4651039 ]\n",
      " [-0.25528326 -0.31609636]\n",
      " [-1.01945498  1.14841503]\n",
      " [-0.15624629 -0.52760103]\n",
      " [ 1.06973549  0.81770119]\n",
      " [ 0.65580143 -0.54864024]]\n",
      "delta [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "weights [[-0.52917959  0.8978584   0.53202206 -0.30065492]\n",
      " [-0.00140496  0.8801534  -0.45064033 -0.62988462]]\n",
      "delta [0. 0.]\n",
      "weights [[ 0.7884142   0.75053325]\n",
      " [-0.93052482  0.44785442]\n",
      " [ 0.51936389  0.86064379]\n",
      " [-0.91060742  0.00364752]]\n",
      "delta [0. 0. 0. 0.]\n",
      "weights [[ 0.91679288 -0.42889059  0.64482757 -0.44963618]\n",
      " [-0.77369134 -1.07115896 -0.94308914 -0.97603992]]\n",
      "delta [0. 0.]\n",
      "weights [[ 1.02485237e+00 -7.31797541e-01 -8.69370820e-01  1.93161325e-01\n",
      "   2.08431962e-01  9.21627423e-01 -1.61373408e-01  1.16633411e+00\n",
      "  -5.02703640e-01  8.84054880e-01 -6.95005331e-01 -1.20708406e+00\n",
      "  -9.61331161e-01]\n",
      " [-3.79030490e-01 -4.41168711e-01 -7.98785583e-01  7.67698402e-01\n",
      "   6.39057431e-01  2.18622572e-01 -4.34297498e-01  7.85038361e-01\n",
      "  -1.99040428e-01  1.04716158e+00 -8.43562668e-01  2.59844768e-01\n",
      "  -8.19068310e-01]\n",
      " [ 5.82541081e-01 -1.17339008e+00  3.67579711e-01 -1.06352526e+00\n",
      "  -4.91590113e-01  5.25138397e-01 -6.50555718e-01  4.96397378e-02\n",
      "  -5.17722107e-01 -8.34455080e-02 -1.04344375e-03  7.26207850e-02\n",
      "  -6.96869712e-01]\n",
      " [-4.71483429e-01 -1.09065696e-01 -9.10831337e-01 -2.07305649e-02\n",
      "   5.20947575e-01 -6.43395072e-01  3.29515294e-01 -7.92465072e-01\n",
      "   9.59168829e-01  1.07334008e+00  1.08592490e+00  1.13855504e+00\n",
      "   1.13659839e-01]]\n",
      "delta [0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input and output layers must be with equal numbers\n",
    "\n",
    "layers = [\n",
    "    Linear(4,13, activation=Sigmoid()),\n",
    "    Linear(13,4, activation=Sigmoid()),\n",
    "    Linear(4,2, activation=Sigmoid()),\n",
    "    Linear(2,4, activation=Sigmoid()),\n",
    "    Linear(4,2, activation=Sigmoid()),\n",
    "    Linear(2,100, activation=Sigmoid()),\n",
    "    Linear(100,1, activation=Sigmoid()),\n",
    "    Linear(1,1, activation=Sigmoid()),\n",
    "    Linear(1,1, activation=Softmax()),\n",
    "]\n",
    "\n",
    "model = Model(layers=layers, loss=MSELoss(), n_epoch=1, verbose=0)\n",
    "\n",
    "\n",
    "model.fit(dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87616528,  0.8770434 , -1.07185091, -0.3473528 ,  0.07240868,\n",
       "        -0.0397271 ,  0.04991074, -1.00090593,  0.99031344,  1.10922691,\n",
       "         0.56103235, -0.71546477,  1.19246648],\n",
       "       [ 0.29093634,  0.58343993,  0.06555826,  0.26530925, -0.87390265,\n",
       "        -0.76867888, -0.39083652, -0.94488054,  0.90105738,  0.65674802,\n",
       "         0.83505957, -0.72995415, -1.15744424],\n",
       "       [ 0.59840803,  0.97942934, -0.92458376, -1.03876575, -0.6212136 ,\n",
       "        -0.08884953,  0.68199734,  0.25303518, -0.47230019,  1.11874919,\n",
       "         0.13748123,  0.1428907 ,  0.72724899],\n",
       "       [-0.09438416, -0.39631527,  0.96266206,  0.61768845, -0.42897597,\n",
       "         1.05387946,  0.50110398,  1.00928054, -0.98790323,  0.02746748,\n",
       "         0.95923375, -0.06502083, -0.64327335]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9391043  0.00322892 0.00930119 0.94782751 0.91798714 0.01339995\n",
      " 0.00372608 0.00276383 0.03399139 0.96232475 0.86889642 0.67765143\n",
      " 0.00543836]\n",
      "\n",
      "[0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (13,) and (4,) not aligned: 13 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[369], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[366], line 58\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mprint\u001b[39m(D[i])\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i]\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[1;32m     61\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(epoch_losses)\n\u001b[1;32m     62\u001b[0m losses_by_epoch\u001b[38;5;241m.\u001b[39mappend(mean_loss)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (13,) and (4,) not aligned: 13 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "model.fit(dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset['data'], dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 1091,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0), np.int64(1), np.int64(2)}"
      ]
     },
     "execution_count": 1093,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set(y)\n",
    "labels_len = len(labels)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1]]"
      ]
     },
     "execution_count": 1094,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 = []\n",
    "\n",
    "for i in y:\n",
    "    l = [0] * labels_len\n",
    "    l[i] = 1\n",
    "    y_1.append(l)\n",
    "y_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y_1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data=X_train, targets=y_train)\n",
    "val_dataset = Dataset(data=X_val, targets=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Linear(4,10, activation=ReLU()),\n",
    "    Linear(10,20, activation=ReLU()),\n",
    "    Linear(20,100, activation=ReLU()),\n",
    "    Linear(100,10, activation=ReLU()),\n",
    "    Linear(10,3, activation=Softmax()),\n",
    "]\n",
    "\n",
    "model = Model(layers=layers, loss=MSELoss(), n_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 100%|██████████| 10/10 [00:00<00:00, 41.55it/s]\n"
     ]
    }
   ],
   "source": [
    "losses = model.fit(dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.3, 3. , 1.1, 0.1])"
      ]
     },
     "execution_count": 1240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.37434921, 0.37134219, 0.2543086 ]]), [1, 0, 0])"
      ]
     },
     "execution_count": 1241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train[1]), y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.23116393, 0.37761343, 0.39122264]]), [0, 1, 0])"
      ]
     },
     "execution_count": 1242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val[1]), y_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3416666666666667"
      ]
     },
     "execution_count": 1270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_count = 0\n",
    "all_count = 0\n",
    "\n",
    "for sample,target in zip(X_train, y_train):\n",
    "    pred = model.predict(sample=sample)\n",
    "\n",
    "    pred = np.where(pred[0] >= max(pred[0]), 1, 0)\n",
    "    # print(pred)\n",
    "    # print(target)\n",
    "\n",
    "    if list(pred) == target:\n",
    "        true_count += 1\n",
    "    all_count += 1 \n",
    "\n",
    "\n",
    "acc = true_count / all_count\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 1215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([1,0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
