{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class activation_functions:\n",
    "\n",
    "    @classmethod\n",
    "    def ReLU(cls, inputs):\n",
    "        return np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample = tuple[list, int]\n",
    "Data = list[Sample]\n",
    "\n",
    "Label = int\n",
    "Labels = list[Label]\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, data: Data) -> None:\n",
    "        self.data: Data = data\n",
    "        self._len = len(data)\n",
    "        self.labels: Labels = [sample[1] for sample in self.data]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n_inputs, n_neurons, activation) -> None:\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_neurons = n_neurons\n",
    "        \n",
    "        self.weights = self._init_weights()\n",
    "        self.biases = self._init_biases()\n",
    "\n",
    "        self.activation = activation\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        return np.random.randn(self.n_inputs, self.n_neurons) * 0.1\n",
    "    \n",
    "    def _init_biases(self):\n",
    "        return np.random.randn(self.n_inputs, self.n_neurons)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = np.dot(inputs, self.weights) + self.biases\n",
    "        self.output = self.activation(output)\n",
    "\n",
    "\n",
    "Layers = list[Layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers: Layers):\n",
    "        self.layers = layers\n",
    "        self._layers_len = len(layers)\n",
    "\n",
    "    def fit(self, dataset: Dataset):\n",
    "        for sample in dataset:\n",
    "\n",
    "            sample_inputs = sample[0]\n",
    "            self.layers[0].forward(inputs=sample_inputs)\n",
    "            \n",
    "            for i in range(1, self._layers_len):\n",
    "                self.layers[i].forward(inputs=self.layers[i-1].output)\n",
    "    \n",
    "    def predict(self):\n",
    "        ...\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights.append(layer.weights)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    ([1,2,3,4], 0),\n",
    "    ([4,3,2,1], 1),\n",
    "]\n",
    "val_data = [\n",
    "    ([1,2,3,4], 0),\n",
    "    ([4,3,2,1], 1),\n",
    "]\n",
    "\n",
    "\n",
    "train_dataset = Dataset(data=train_data)\n",
    "val_dataset = Dataset(data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Layer(len(train_data[0][0]), len(train_data[0][0]), activation=activation_functions.ReLU),\n",
    "    Layer(len(train_data[0][0]), 2, activation=activation_functions.ReLU),\n",
    "]\n",
    "\n",
    "model = NeuralNetwork(layers=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03031103,  0.07898614,  0.1177167 ,  0.00634622],\n",
       "        [-0.02145522,  0.05751183,  0.01661315,  0.12067534],\n",
       "        [-0.1213195 ,  0.08327413, -0.05483704,  0.12121379],\n",
       "        [ 0.02938154,  0.0623912 , -0.09240622, -0.04876877]]),\n",
       " array([[-0.0161988 ,  0.02131159],\n",
       "        [-0.01281915, -0.00060539],\n",
       "        [ 0.14546464,  0.09620433],\n",
       "        [ 0.01192194,  0.06019809]])]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04662128,  0.00362523,  0.11101263,  0.21666945],\n",
       "        [-0.0427738 , -0.02047442,  0.00652623,  0.12543406],\n",
       "        [ 0.04504755, -0.13728407,  0.14258488, -0.1006611 ],\n",
       "        [-0.21504161, -0.09286219,  0.02443559, -0.06513455]]),\n",
       " array([[ 0.01747982,  0.05444045],\n",
       "        [ 0.05884424, -0.05411848],\n",
       "        [-0.07776638,  0.02290638],\n",
       "        [ 0.02842925,  0.12456388]])]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
